{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e15ab925-fc06-4c2f-9bb2-48fd528c4431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 12:07:14.181951: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-06 12:07:14.277229: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-06 12:07:14.547901: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-06 12:07:14.547973: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-06 12:07:14.550822: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-06 12:07:14.791499: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-06 12:07:14.794549: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-06 12:07:15.844576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1a032c-93a3-46d5-8b9d-de83175a32a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "dataframe = pd.read_csv('train.csv')#.iloc[:330]\n",
    "image_names = dataframe['image_name'].values\n",
    "targets = dataframe['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "645642dc-0877-4c6b-978d-94b0e9e15c37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_names, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698a4027-b99a-4557-894c-595fc6f06ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a data generator for augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06595271-a71c-4162-bac8-7f5011fc4f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a115d6ce-9d7d-436c-8d31-224d15058ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_dcm_image(file_path):\n",
    "    dcm_image = pydicom.dcmread(file_path+\".dcm\")\n",
    "    image_array = dcm_image.pixel_array\n",
    "    image_array = Image.fromarray(image_array)\n",
    "    image_array = image_array.resize((224, 224))  # Resize to the input size of the neural network\n",
    "    return np.array(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd323d05-e4c0-4e37-a5aa-76afb3c4b1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dir containing images\n",
    "image_directory = 'train/'\n",
    "\n",
    "# Convert image names to full paths\n",
    "X_train_paths = [os.path.join(image_directory, fname) for fname in X_train]\n",
    "X_test_paths = [os.path.join(image_directory, fname) for fname in X_test]\n",
    "\n",
    "# Create image arrays\n",
    "#X_train_images = np.array([load_dcm_image(path) for path in X_train_paths])\n",
    "#X_test_images = np.array([load_dcm_image(path) for path in X_test_paths])\n",
    "\n",
    "# Save for future use\n",
    "#np.save('X_train_images.npy', X_train_images)\n",
    "#np.save('X_test_images.npy', X_test_images)\n",
    "\n",
    "# load arrays\n",
    "X_train_images = np.load('X_train_images.npy')\n",
    "X_test_images = np.load('X_test_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd3c13a-8e0e-4521-a5a9-296539e44262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 12:07:25.267833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 12:07:25.270111: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)  # Load MobileNetV2 without the top layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # New FC layer, output layer\n",
    "embeddings = Dense(128, activation='relu')(x)  # This will be our embeddings\n",
    "predictions = Dense(1, activation='sigmoid')(embeddings)  # Final prediction layer\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4060784b-f4a4-40aa-a027-b2d2459707e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eab3f20-55c7-4a4b-afbb-c8f0fb70cdfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethan/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setup checkpoint to save the best model\n",
    "checkpoint = ModelCheckpoint('best_model.h5', verbose=1, save_best_only=True)\n",
    "model.save('pretrain_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f629742-814b-4e3e-a1f0-e8f3081bf6c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6626, 224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6cdd40-2c78-4c39-8498-65f2ee69f406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure the generators to use the image data and the labels\n",
    "train_generator = train_datagen.flow(\n",
    "    X_train_images, y_train, batch_size=32\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow(\n",
    "    X_test_images, y_test, batch_size=32\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=len(X_train_images) // 32,\n",
    "    validation_steps=len(X_test_images) // 32,\n",
    "    epochs=10,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "model.save('posttrain_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f3f42-d940-44ab-a536-c12b346243cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d8121-9175-4c5b-8de3-60cea2cfece7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.summary() # get layer name of 2nd to last layer (layer before predicitons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4177bd-d689-43e8-ac07-fc7fbb281170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill in name of layer we want to extract embeddings from\n",
    "embedding_layer_name = 'dense_4' \n",
    "\n",
    "embedding_model = Model(inputs=best_model.input, outputs=best_model.get_layer(embedding_layer_name).output)\n",
    "\n",
    "# Save the embedding model\n",
    "embedding_model.save('embedding_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c7e58-0e4d-4e1d-ab68-413846bdc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and save embeddings\n",
    "train_embeddings = embedding_model.predict(train_datagen.flow(X_train_images))\n",
    "test_embeddings = embedding_model.predict(test_datagen.flow(X_test_images))\n",
    "\n",
    "# Save the embeddings\n",
    "np.save('train_embeddings.npy', train_embeddings)\n",
    "np.save('test_embeddings.npy', test_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b8df15-b79d-4dfd-a130-229c6b40966d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6958b-cacf-403a-9a1a-44183af007bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
